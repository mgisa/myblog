[
  {
    "path": "posts/2022-02-21-unesco-mab-pgm/",
    "title": "50th Anniversary of UNESCO's MAB Programme",
    "description": "This is an executive summary of the talk presentation given to the different types of audience attended the 50th anniversary of UNESCO's MAB Programme. This is an intergovernmental scientific programme that aims to establish a scientific basis for enhancing the relationship between people and their environments. It combines the natural and social sciences with a view to improving human livelihoods and safeguarding natural and managed ecosystems, thus promoting innovative approaches to economic development that are socially and culturally appropriate and environmentally sustainable.",
    "author": [
      {
        "name": "Murera Gisa",
        "url": "https://rpubs.com/mgisa"
      }
    ],
    "date": "2022-02-21",
    "categories": [
      "talk",
      "tidyverse"
    ],
    "contents": "\r\n\r\nContents\r\nOverview\r\nAbstract\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n blog post\r\n\r\nOverview\r\nThe world day celebration of 50th anniversary of UNESCO Man and Biosphere (MAB) Program that aims to raise the awareness in environmental protection and create the free-pollution communities around the world.\r\nAbstract\r\nIn this workshop, Murera Gisa discuss how the data science technology should be used to protect the environment by focussing on the air quality data analysis, visualization and information dissemination through the developed Indoor Air Quality monitoring tools. We demonstrate handy functions in usethis, devtools,openairand other R built-in libraries and strategical packages for the entire data analysis workflow to the monitoring tool deployment and publicly avail it for policy implimentation.\r\nThe speaker share the other blog done on the Impact of Weather Conditions on Air Pollution Concentration which can be found Here to clearly show how data analytics might relevently identify the insightful information hidden from data and support the mitigation policy implimentation.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-02-21-unesco-mab-pgm/poster.png",
    "last_modified": "2022-05-31T15:58:55+02:00",
    "input_file": {},
    "preview_width": 1306,
    "preview_height": 1302
  },
  {
    "path": "posts/2021-10-15-game-of-throne/",
    "title": "#GOT Animating the Shifting of Affiliations on Amazing Movie",
    "description": "My first steps using the gganimate package using Game of Thrones \ndata!",
    "author": [
      {
        "name": "Murera Gisa",
        "url": "http://rpubs.com/mgisa"
      }
    ],
    "date": "2021-10-18",
    "categories": [
      "data-visualization",
      "ggplot2",
      "animation"
    ],
    "contents": "\r\n\r\nContents\r\nDisclaimers\r\nIntroduction and Idea\r\nThe data, the wrangling and the cleaning\r\nAffiliations Positions\r\nCharacter positions\r\nSome details before the magic\r\nAnimation is HERE\r\n\r\n\r\n\r\n\r\nFigure 1: gganimate: worth to try it and learn it\r\n\r\n\r\n\r\nDisclaimers\r\nI know the animation is not then best way to visualiza data! Don’t judge me please! But is fun to play with.\r\nI don’t follow the series so I don’t know if the results or animations makes any sense.\r\nIntroduction and Idea\r\nWhy use GOT data? Because I was participating in #datosdemiercoles which is the spanish version of #tidytuesday. So the data is given and the purpouse is to learn new packages using that data and share with the community, you know this already, right?\r\nSecondly the package I want to learn beside {ggforce} is {gganimate} so a very first idea was represent every character as a point and move according the actual affiliations. A kind of copy inspiration from FlowingData’s A Day in the Life of Americans1\r\n\r\nInspiration by Flowindata\r\n\r\n\r\n\r\nThe data, the wrangling and the cleaning\r\nThe data come from this post where the shifting affiliations are visualized using an alluyvial diagram. It’s a nice post by Matthew Lunkes where he tell all the process to get the final chart:\r\n\r\n\r\n\r\nFigure 2: Chart by Matthew Lunkes\r\n\r\n\r\n\r\nIn this case the data can be downloaded from this repository https://github.com/MattLunkes/GoT_Affiliations.\r\n\r\n\r\nlibrary(tidyverse)\r\ndata <- read_csv(\"https://raw.githubusercontent.com/MattLunkes/GoT_Affiliations/master/got_char.csv\")\r\ndata\r\n\r\n\r\n# A tibble: 488 × 11\r\n   Name   Origin  `Starting Affil… `End of S1` `End of S2` `End of S3`\r\n   <chr>  <chr>   <chr>            <chr>       <chr>       <chr>      \r\n 1 Tyrio… House … King Robert Bar… King Joffr… King Joffr… King Joffr…\r\n 2 Cerse… House … King Robert Bar… King Joffr… King Joffr… King Joffr…\r\n 3 Daene… House … Viserys Targary… Daenerys T… Daenerys T… Daenerys T…\r\n 4 Jon S… House … King Robert Bar… Night's Wa… Wildlings   Night's Wa…\r\n 5 Sansa… House … King Robert Bar… King Joffr… King Joffr… King Joffr…\r\n 6 Arya … House … King Robert Bar… Other, Wes… Other, Wes… Other, Wes…\r\n 7 Jaime… House … King Robert Bar… King Joffr… King Joffr… King Joffr…\r\n 8 Jorah… House … Viserys Targary… Daenerys T… Daenerys T… Daenerys T…\r\n 9 Theon… House … King Robert Bar… Robb Stark… Balon Grey… King Joffr…\r\n10 Samwe… House … Night's Watch    Night's Wa… Night's Wa… Night's Wa…\r\n# … with 478 more rows, and 5 more variables: End of S4 <chr>,\r\n#   End of S5 <chr>, End of S6 <chr>, End of S7 <chr>, Episodes <dbl>\r\n\r\nAs we see, the data comes in a not tidy way so gather is our friend here.\r\n\r\n\r\ndata_long <- data %>%\r\n  janitor::clean_names() %>% \r\n  rename(end_of_s0 = starting_affiliation) %>%\r\n  select(-episodes, -origin) %>% \r\n  gather(season, affiliation, -name) %>% \r\n  mutate(\r\n    season = as.numeric(str_extract(season, \"\\\\d+\")),\r\n    affiliation = case_when(\r\n      affiliation == \"King Robert Baratheon\" ~ \"Baratheon\",\r\n      affiliation == \"Viserys Targaryen\" ~ \"Targaryen\",\r\n      affiliation == \"King Joffrey Baratheon\" ~ \"Lannister\",\r\n      affiliation == \"Daenerys Targaryen\" ~ \"Targaryen\",\r\n      affiliation == \"Night's Watch\" ~ \"Night's Watch\",\r\n      affiliation == \"Other, Westeros\" ~ \"Westeros\",\r\n      affiliation == \"Wildlings\" ~ \"Wildlings\",\r\n      affiliation == \"King Tommen Baratheon\" ~ \"Lannister\",\r\n      affiliation == \"Petyr Baelish, Lord Protector of the Vale\" ~ \"The Vale\",\r\n      affiliation == \"Other, Essos\" ~ \"Essos\",\r\n      affiliation == \"Roose Bolton, Lord Paramount of the North\" ~ \"Bolton\",\r\n      affiliation == \"Queen Cersei Lannister\" ~ \"Lannister\",\r\n      affiliation == \"Jon Snow, King in the North\" ~ \"Stark\",\r\n      TRUE ~ affiliation\r\n      )\r\n    )\r\n# there are some repeated characters?\r\ndata_long <- data_long %>% \r\n  dplyr::semi_join(count(data, Name) %>% filter(n == 1), by = c(\"name\" = \"Name\")) %>% \r\n  # importante for the ggrepel part\r\n  arrange(season, name, affiliation)\r\ndata_long\r\n\r\n\r\n# A tibble: 3,592 × 3\r\n   name            season affiliation  \r\n   <chr>            <dbl> <chr>        \r\n 1 Addam Marbrand       0 Baratheon    \r\n 2 Adrack Humble        0 Baratheon    \r\n 3 Aeron Greyjoy        0 Baratheon    \r\n 4 Aggo                 0 Khal Drogo   \r\n 5 Alliser Thorne       0 Night's Watch\r\n 6 Alton Lannister      0 Baratheon    \r\n 7 Alys Karstark        0 Baratheon    \r\n 8 Amory Lorch          0 Baratheon    \r\n 9 Anara                0 Essos        \r\n10 Anguy                0 Baratheon    \r\n# … with 3,582 more rows\r\n\r\nAffiliations Positions\r\nAt the beginning I think use a circular layout and see what happend but the result was far for beign interesting, and as we can see I was a failure in my first attempt using {gganimate}.\r\n\r\n\r\n\r\nFigure 3: #notsogood @accidental__art\r\n\r\n\r\n\r\n\r\n\r\n\r\nvia GIPHY\r\n\r\nWell, so the next idea and step was to get closer the affilations related. How can be two affiliations be related? An answer can be the the amount of characters which move from one to another.\r\n\r\n\r\nts <- data_long %>% \r\n  distinct(season) %>% \r\n  pull() %>% \r\n  head(-1)\r\nchange_season <- map_df(ts, function(t = 0){\r\n  \r\n  full_join(\r\n    data_long %>% filter(season == t),\r\n    data_long %>% filter(season == t + 1),\r\n    by = \"name\", \r\n    suffix = c(\"_before\", \"_actual\")\r\n  ) %>% \r\n    count(from = affiliation_before, to = affiliation_actual) %>% \r\n    filter(complete.cases(.)) %>% \r\n    mutate(season = t)\r\n  \r\n})\r\nchange_total <- change_season %>% \r\n  group_by(from, to) %>% \r\n  summarise(n = sum(n)) %>% \r\n  ungroup()\r\nchange_total\r\n\r\n\r\n# A tibble: 119 × 3\r\n   from                                    to                        n\r\n   <chr>                                   <chr>                 <int>\r\n 1 Balon Greyjoy, King of the Iron Islands Balon Greyjoy, King …    31\r\n 2 Balon Greyjoy, King of the Iron Islands Deceased                  7\r\n 3 Balon Greyjoy, King of the Iron Islands Euron Greyjoy, King …     4\r\n 4 Balon Greyjoy, King of the Iron Islands Lannister                 1\r\n 5 Balon Greyjoy, King of the Iron Islands Targaryen                 3\r\n 6 Baratheon                               Balon Greyjoy, King …     9\r\n 7 Baratheon                               Brotherhood Without …     5\r\n 8 Baratheon                               Deceased                 15\r\n 9 Baratheon                               Essos                     1\r\n10 Baratheon                               House Arryn (Neutral)    12\r\n# … with 109 more rows\r\n\r\nNow, with this data we can use the {igraph} package and the graph_from_data_frame function to get a graph from the previous data frame and then get a layout.\r\n\r\n\r\nlibrary(igraph)\r\ng <- graph_from_data_frame(change_total, directed = FALSE)\r\n# https://igraph.org/r/doc/strength.html\r\nE(g)$weight <- pull(change_total, n)\r\nV(g)$degree <- degree(g)\r\nV(g)$label.cex <- 0.5\r\nplot(g)\r\n\r\n\r\n\r\n\r\nNice! but we need the positions instead of the image. So we’ll use the layout_with_fr to get some layout of our graph.\r\n\r\n\r\nset.seed(123)\r\nlayout <- layout_with_fr(g)\r\naffiliations <- tibble(\r\n  affiliation = V(g)$name,\r\n  x = layout[, 2],\r\n  y = layout[, 1],\r\n  degree = degree(g)\r\n)\r\naffiliations <- data_long %>% \r\n  count(affiliation) %>% \r\n  left_join(affiliations, ., by = \"affiliation\")\r\naffiliations\r\n\r\n\r\n# A tibble: 27 × 5\r\n   affiliation                                   x      y degree     n\r\n   <chr>                                     <dbl>  <dbl>  <dbl> <int>\r\n 1 Balon Greyjoy, King of the Iron Islands -1.28    0.105      9    46\r\n 2 Baratheon                               -0.695   0.361     11   200\r\n 3 Bolton                                  -0.205   0.388      5    18\r\n 4 Brotherhood Without Banners              0.0145  0.743      6    52\r\n 5 Deceased                                -0.421  -0.360     26   826\r\n 6 Dothraki                                -1.09   -1.49       6   100\r\n 7 Essos                                   -0.229  -0.782     16   262\r\n 8 Essos Slavers                           -0.200  -1.44       6   113\r\n 9 Euron Greyjoy, King of the Iron Islands -2.08    0.617      2     4\r\n10 High Sparrow                            -1.37   -0.319      4     7\r\n# … with 17 more rows\r\n\r\nAt this point we are ready to use ggplot and check!\r\n\r\n\r\np1 <- ggplot(affiliations, aes(x, y, color = affiliation, label = affiliation, size = degree)) +\r\n  geom_point() +\r\n  geom_text() +\r\n  scale_size(range = c(1, 4)) +\r\n  theme(legend.position = \"none\") +\r\n  labs(title = \"igraph laytout\")\r\np1\r\n\r\n\r\n\r\n\r\nThis is really an improvement from the the circular layout. The downside is the main affiliations are too close so the text is overlaping. A simple solution to this was generate an equidistant sequence for every set of coordinates, \\(x\\) and \\(y\\).\r\n\r\n\r\naffiliations <- affiliations %>% \r\n  arrange(y) %>% \r\n  mutate(y = seq(1:n())) %>% \r\n  arrange(x) %>% \r\n  mutate(x = seq(1:n())) %>% \r\n  mutate_at(vars(x, y), ~ (.x - mean(.x))/sd(.x))\r\n\r\n\r\n\r\nWe can compare the results:\r\n\r\n\r\n\r\nHappy with the effect of a simple fix for the overlaping text. And I think this change keep the spirit of the original graph’s shape.\r\nCharacter positions\r\nTo get the character positions for every step/time/season we decided to put them in the corresponding affiliation making a circle around it and then adding a random noise\r\n\r\n\r\nget_reg_poly_coords <- function(sides = 5, radius = 1, x0 = 0, y0 = 0) {\r\n  # https://stackoverflow.com/a/7198179/829971\r\n  x <- radius * cos(2*pi*(1:sides)/sides) + x0\r\n  y <- radius * sin(2*pi*(1:sides)/sides) + y0\r\n  return(tibble(x, y))\r\n}\r\ncharacters <- data_long %>% \r\n  count(season, affiliation) %>%\r\n  mutate(coords = map2(n, 1/nrow(affiliations), get_reg_poly_coords)) %>% \r\n  unnest(cols=c(coords)) %>% \r\n  select(-season, -affiliation) %>% \r\n  bind_cols(data_long, .) %>% \r\n  left_join(affiliations, by = c(\"affiliation\"),  suffix = c(\".character\", \".affiliation\")) %>% \r\n  mutate(\r\n    x = x.character +  x.affiliation,\r\n    y = y.character +  y.affiliation\r\n  ) %>% \r\n  mutate_at(vars(x, y), ~ .x + runif(length(.x), -1, 1)/nrow(affiliations))\r\n\r\n\r\n\r\n\r\n\r\np <- ggplot() +\r\n  geom_point(aes(x, y, color = affiliation), alpha = 0.5, data = characters) +\r\n  geom_text(aes(x, y, size = n, label = affiliation), alpha = 0.5, data = affiliations) +\r\n  scale_size_area() +\r\n  scale_color_viridis_d() +\r\n  theme(legend.position = \"none\")\r\np\r\n\r\n\r\n\r\n\r\nNice! We are almost there.\r\nSome details before the magic\r\nTo get a very style GOT theme we need first the font, you can download from this link https://fontmeme.com/fonts/game-of-thrones-font/.[Thanks to (violetrzn)[https://twitter.com/violetrzn], https://github.com/violetr/tidytuesday/blob/master/datosdem2.R#L8] and use it with the {extrafont} package.\r\nWe’ll select some important characters to use with {ggrepel} package:\r\n\r\n\r\nmain_characters <- data %>%\r\n  select(name = Name, Episodes) %>% \r\n  arrange(desc(Episodes)) %>%\r\n  head(5)\r\nknitr::kable(main_characters)\r\n\r\n\r\nname\r\nEpisodes\r\nTyrion Lannister\r\n61\r\nCersei Lannister\r\n58\r\nDaenerys Targaryen\r\n56\r\nJon Snow\r\n56\r\nSansa Stark\r\n54\r\n\r\nAnimation is HERE\r\nFirst we need some setup for the font and colors.\r\n\r\n\r\nlibrary(extrafont)\r\nloadfonts() # yeah, win! :/\r\nfont <- \"Game of Thrones\"\r\nfont2 <- \"Roboto Condensed\"\r\nbckground <- #AB892C\r\ncolor1 <- \"#959394\"\r\ncolor2 <- \"white\"\r\nseed <- 12345\r\n\r\n\r\n\r\nThen, the usual {ggplot2} syntax.\r\n\r\n\r\np <- ggplot() +\r\n  # maint characters labels\r\n  ggrepel::geom_text_repel(\r\n  # geom_text(\r\n    aes(x, y, label = name),\r\n    seed = seed,\r\n    # box.padding = .5, force = 0.25,, max.iter = 5000,\r\n    color = color1,\r\n    size = 3,\r\n    family = font2,\r\n    vjust = \"inward\", hjust = \"inward\",\r\n    data = dplyr::semi_join(characters, main_characters, by = \"name\")\r\n  ) +\r\n  # https://stackoverflow.com/a/34398935/829971\r\n  # maint characters points\r\n  geom_point(\r\n    aes(x, y),\r\n    size = 3,\r\n    alpha = 0.50,\r\n    color = color2,\r\n    stroke = 0,\r\n    shape = 16,\r\n    data = semi_join(characters, main_characters, by = \"name\")\r\n  ) +\r\n  # rest of points\r\n  geom_point(\r\n    aes(x, y),\r\n    size = 3,\r\n    alpha = 0.20,\r\n    color = color2,\r\n    stroke = 0,\r\n    shape = 16,\r\n    data = dplyr::anti_join(characters, main_characters, by = \"name\") \r\n  ) +\r\n  # labels affiliations\r\n  geom_text(\r\n    aes(x, y + 3 / nrow(affiliations), label = affiliation, size = degree),\r\n    data = affiliations,\r\n    color = color1,\r\n    alpha = 0.80,\r\n    family = font\r\n  ) +\r\n  scale_size(range = c(2, 5)) +\r\n  labs(\r\n    title = \"#\",\r\n    caption = \"#DataBrain\",\r\n    x = NULL,\r\n    y = NULL\r\n  ) +\r\n  theme(\r\n    legend.position = \"none\",\r\n    panel.border = element_blank(),\r\n    panel.background = element_blank(),\r\n    panel.grid = element_blank(),\r\n    axis.text.x = element_blank(),\r\n    axis.text.y = element_blank(),\r\n    axis.ticks = element_blank(),\r\n    rect = element_rect(fill = bckground, color = bckground),\r\n    text  = element_text(family = font, colour = color1, size = 15),\r\n    plot.title = element_text(family = font, colour = color1, size = 25),\r\n    plot.subtitle = element_text(family = font2, colour = color1, size = 13),\r\n    plot.caption = element_text(family = font2, colour = color1, size = 10),\r\n  )\r\n\r\n\r\n\r\nFinally add the {gganimate} magic:\r\n\r\n\r\nlibrary(gifski)\r\nlibrary(av)\r\nlibrary(gganimate)\r\n\r\np <- p +\r\n  labs(subtitle = \"Affiliation changes in season {trunc(frame_time)}\") +\r\n  transition_time(season) +\r\n  shadow_wake(wake_length = 0.005, alpha = TRUE, exclude_layer = 1) +\r\n  ease_aes(\"exponential-in-out\")\r\n\r\n\r\n\r\nFor test purposes I recommend reduce de fps to 10, and duration as much you can according how many frames you are using so you can to check if the output animation is what you want quickly, then for the final output use at least 30 fps to get a smooth transition.\r\n\r\n\r\nanimate(p, fps = 30, duration = 8*3, width = 1000, height = 800)\r\n\r\n\r\n\r\nAnd voilà:\r\n\r\n\r\n\r\n\r\nhttps://flowingdata.com/2015/12/15/a-day-in-the-life-of-americans/↩︎\r\n",
    "preview": "posts/2021-10-15-game-of-throne/preview2.jpg",
    "last_modified": "2022-05-31T15:58:55+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-14-the-sharpe-ratio/",
    "title": "The Sharpe Ratio",
    "description": "In this post we present a classic finance use case using the PerformanceAnalytics, quantmod, and dygraphs packages. We'll demonstrate importing stock data, building a portfolio, and then calculating the Sharpe Ratio.",
    "author": [
      {
        "name": "Murera Gisa",
        "url": "https://rpubs.com/mgisa"
      }
    ],
    "date": "2020-09-10",
    "categories": [
      "portfolio theory",
      "dygraphs"
    ],
    "contents": "\r\n\r\nContents\r\nOverview\r\nSetting up\r\nPreparing the data\r\nCalculating portfolio returns\r\nCalculating the Sharpe Ratio\r\n\r\n\r\n\r\n\r\nOverview\r\nIn this post we’ll demonstrate the calculation of a Sharpe Ratio for a stock portfolio. We’ll start with a function that grabs monthly stock returns and saves those monthly returns as an xts object in the global environment. With that function, we will create three xts objects of monthly returns, and merge those three xts objects into one object, before passing that merged object to dygraphs to peek at the individual stocks.\r\nThen, we’ll move on to build a portfolio by selecting asset weights and calculating the portfolio monthly returns. Next, we will calculate the growth of a dollar invested in that portfolio (which is what matters to us) over time, and save the results to an xts object. Dygraphs will come in handy again for the portfolio visualizations. Finally, we will calculate the Sharpe Ratio.\r\nSetting up\r\nWe start by loading three packages: quantmod to download the data, PerformanceAnalytics to run portfolio calculations, and dygraphs to graph time series objects. We will also create a function to import stock data.\r\n\r\n\r\nlibrary(PerformanceAnalytics)\r\nlibrary(quantmod)\r\nlibrary(dygraphs)\r\n# Function to calculate monthly returns on a stock \r\nmonthly_stock_returns <- function(ticker, start_year) {\r\n  \r\n  # Download the data from Yahoo finance\r\n  symbol <- getSymbols(ticker, src = 'yahoo', \r\n                       auto.assign = FALSE, warnings = FALSE)\r\n  \r\n  # Tranform it to monthly returns using quantmode::periodReturn\r\n  data <- periodReturn(symbol, period = 'monthly', \r\n                       subset=paste(start_year, \"::\", sep = \"\"),\r\n                       type = 'log')\r\n  # Let's rename the column of returns to something intuitive because\r\n  # the column name is what will eventually be displayed\r\n  colnames(data) <- as.character(ticker)\r\n  # We want to be able to work with the xts objects so let's explicitly\r\n  # assign them into the global environment using ticker name \r\n  assign(ticker, data, .GlobalEnv)\r\n}\r\n\r\n\r\n\r\nThe monthly_stock_returns function above takes 2 parameters, a stock symbol and a year. Note that we could have included a third parameter called something like ‘period’ if we wanted the ability to grab periods other than monthly returns. For example, we can envision a desire to look at annual, weekly or daily returns. Here, I force monthly returns because I don’t want to allow different period options. It’s a choice driven by the purpose of this Notebook - which here is focused on monthly returns.\r\nPreparing the data\r\nIn the next chunk, we choose three stock tickers and a starting year argument for the monthly_stock_returns function. Then, we merge them into one xts object.\r\n\r\n\r\n# Choose the starting year and assign it to the 'year' variable\r\nyear <- 2010\r\n# Use the function the monthly returns on 3 stocks, and pass in the 'year'\r\n# value. Let's choose Google, JP Morgan and Amazon\r\nmonthly_stock_returns('GOOG', year)\r\nmonthly_stock_returns('JPM', year)\r\nmonthly_stock_returns('AMZN', year)\r\n# Merge the 3 monthly return xts objects into 1 xts object.\r\nmerged_returns <- merge.xts(GOOG, JPM, AMZN)\r\n\r\n\r\n\r\nLet’s graph the individual performances of each stock over time.\r\n\r\n\r\n# Before we combine these into a portfolio, graph the individual returns\r\n# and see if anything jumps out as unusual. It looks like something \r\n# affected Google in March of 2014, but didn't affect JP Morgan or Amazon.\r\ndygraph(merged_returns, main = \"Google v JP Morgan v Amazon\") %>%\r\n  dyAxis(\"y\", label = \"%\") %>%\r\n  dyOptions(colors = RColorBrewer::brewer.pal(3, \"Set2\"))\r\n\r\n\r\n\r\n\r\nNothing earth-shattering thus far: we have an xts object of three time series and have seen that one of them had weird behavior in April of 2014 (a Google stock split). We’ll ignore that behavior for this example and go on to constructing a portfolio.\r\nCalculating portfolio returns\r\nHere we’ll find the monthly returns of a weighted combination of assets. Unsurprisingly, we start out by choosing those weights.\r\n\r\n\r\n# We have the 3 monthly returns saved in 1 object.\r\n# Now, let's choose the respective weights of those 3.\r\n# Here we'll allocate 25% to Google, 25% to JP Morgan and 50% to Amazon.\r\nw <- c(.25, .25, .50)\r\n# Now use the built in PerformanceAnalytics function Return.portfolio\r\n# to calculate the monthly returns on the portfolio,\r\nportfolio_monthly_returns <- Return.portfolio(merged_returns, weights = w)\r\n# Use dygraphs to chart the portfolio monthly returns.\r\ndygraph(portfolio_monthly_returns, main = \"Portfolio Monthly Return\") %>%\r\n  dyAxis(\"y\", label = \"%\")\r\n\r\n\r\n\r\n\r\nNow, instead of looking at monthly returns, let’s look at how One dollar would have grown in this portfolio.\r\n\r\n\r\n# Add the wealth.index = TRUE argument and, instead of monthly returns,\r\n# the function will return the growth of $1 invested in the portfolio.\r\ndollar_growth <- Return.portfolio(merged_returns, weights = w, \r\n                                  wealth.index = TRUE)\r\n# Use dygraphs to chart the growth of $1 in the portfolio.\r\ndygraph(dollar_growth, main = \"Growth of $1 Invested in Portfolio\") %>%\r\n  dyAxis(\"y\", label = \"$\")\r\n\r\n\r\n\r\n\r\nA dollar would have grown quite nicely in this portfolio about 2.5x fantastic.\r\nCalculating the Sharpe Ratio\r\nNow let’s look at the risk/reward of this portfolio by calculating the Sharpe Ratio. Briefly, the Sharpe Ratio is the mean of the excess monthly returns above the risk-free rate, divided by the standard deviation of the excess monthly returns above the risk-free rate. This is the formulation of the Sharpe Ratio as of 1994; if we wished to use the original formulation from 1966 the denominator would be the standard deviation of portfolio monthly returns. Learn more here.\r\nIn other words, the Sharpe Ratio measures excess returns per unit of volatility, where we take the standard deviation to represent portfolio volatility. The Sharpe Ratio was brought to us by Bill Sharpe - arguably the most important economist for modern investment management as the creator of the Sharpe Ratio, CAPM and Financial Engines, a forerunner of today’s robo-advisor movement.\r\nIn the code chunk below, we’ll calculate the Sharpe Ratio in two ways.\r\nFirst, we’ll use the Return.excess function from PerformanceAnalytics to calculate a time series of monthly excess returns. Two arguments need to be supplied: the time series of returns and the risk-free rate. The function will return a time series of excess returns, and we’ll take the mean of that time series to get the numerator of the Sharpe Ratio. Then we’ll divide by the standard deviation of the that time series to get the Sharpe Ratio.\r\nOur second method is a bit easier. We’ll use the SharpeRatio function in PerformanceAnalytics, for which we’ll supply two arguments: a time series of monthly returns and risk-free rate.\r\nFor both methods I use a risk-free rate of .03% as the approximate mean of the 1-month Treasury bill rate since 2010. I’ll cover a quick way to grab this and other data via Quandl in a future post.\r\n\r\n\r\n# Method 1: use the Return.excess function from PerformanceAnalytics,\r\n# then calculate the Sharpe Ratio manually.\r\nportfolio_excess_returns <- Return.excess(portfolio_monthly_returns, \r\n                                          Rf = .0003)\r\nsharpe_ratio_manual <- round(\r\n  mean(portfolio_excess_returns) / StdDev(portfolio_excess_returns), 4\r\n)\r\n# If we wanted to use the original, 1966 formulation of the Sharpe Ratio,\r\n# there is one small change to the code in Method 1\r\nsharpe_ratio <- round(\r\n  SharpeRatio(portfolio_monthly_returns, Rf = .0003), 4\r\n)\r\n\r\n\r\n\r\nUsing the Return.excess function and then dividing by the standard deviation of excess returns, the Sharpe Ratio is\r\n\r\n\r\nsharpe_ratio_manual[,1] = sharpe_ratio_manual[,1]\r\n\r\n\r\n\r\nUsing the built in SharpeRatio function, the Sharpe Ratio is\r\n\r\n\r\nsharpe_ratio[1,] = sharpe_ratio[1,]\r\n\r\n\r\n\r\nAlright, we have built a portfolio and calculated the Sharpe Ratio - and also set up some nice reusable chunks for data import, portfolio construction and visualization. We haven’t done anything terribly complex but this can serve as a useful paradigm to any collaborators, including our future selves, who want to reproduce this work, learn from this work, or expand upon this work.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-14-the-sharpe-ratio/preview.png",
    "last_modified": "2022-05-31T15:58:55+02:00",
    "input_file": {},
    "preview_width": 1736,
    "preview_height": 1076
  }
]
