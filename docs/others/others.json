[
  {
    "path": "others/2022-11-12-interpretation-of-ML-outputs/",
    "title": "Explaining AI Visualization(ModelStudio)",
    "description": "This post is inspired by the model and post written by Matt Dancho and being repricated on other data set to ultimately interprete the outputs of ML nodel in visual and most understandable way. \n'Machine learning is great, until you have to explain it': Matt Dancho has said,",
    "author": [
      {
        "name": "Murera Gisa",
        "url": "https://rpubs.com/mgisa"
      }
    ],
    "date": "2022-11-12",
    "categories": [
      "Machine Learning",
      "modelStudio",
      "tidyverse",
      "DALEX"
    ],
    "contents": "\r\n\r\nContents\r\nOverview\r\nSteps and Workflow\r\nStep1: Loading data and Libaries\r\nStep2: Make a Predictive Model\r\nStep3: Make Explainer\r\nStep4: Run modelStudio\r\nAcknowledgement\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n RPubs blog posts modelStudio\r\n\r\nOverview\r\nThis small blog post is aiming to visual explain the output of trained and won machine learning model through the usage of modelstudio library created by Matt Dancho and being hosted in CRAN.\r\nmodelStudio is a new R package that makes it easy to interactively explain machine learning models using state-of-the-art techniques like Shapley Values, Break Down plots, and Partial Dependence (Matt Dancho, 2022).\r\nSteps and Workflow\r\nIn this blog, we will learn how to make my 4 most important Explainable AI plots:\r\nFeature Importance\r\nBreak Down Plot\r\nShapley Values\r\nPartial Dependence\r\nStep1: Loading data and Libaries\r\nLoad the libraries and Data\r\nLoad Libraries: Load modelStudio , DALEX, tidyverse and tidymodels.\r\nImport Data: We’re using the mpg dataset that comes with ggplot2.\r\n\r\n\r\n\r\nlibrary(modelStudio)\r\nlibrary(tidyverse)\r\nlibrary(DALEX)\r\nlibrary(tidymodels)\r\n\r\ndata<- rio::import(\"C:/Users/jmurera/Desktop/Blog/myblog/data/Breast_cancer_data.csv\")\r\n\r\ndata_tbl<-data%>% mutate_if(is.integer, as.factor) %>% as.tibble()\r\n\r\n\r\nThe data to be used looks like this\r\n\r\n\r\nlibrary(flextable)\r\nft <- flextable(head(data_tbl))\r\nft <- autofit(ft)\r\n\r\nfor(i in 1:1){\r\n  flextable_to_rmd(ft)\r\n}\r\n\r\nmean_radiusmean_texturemean_perimetermean_areamean_smoothnessdiagnosis17.9910.38122.801,001.00.11840020.5717.77132.901,326.00.08474019.6921.25130.001,203.00.10960011.4220.3877.58386.10.14250020.2914.34135.101,297.00.10030012.4515.7082.57477.10.127800\r\n\r\nWe want to understand how breast cancer diagnosis status can be estimated based on the remaining 5 columns.\r\nStep2: Make a Predictive Model\r\nThe best way to understand what affects cancer diagnosis decision is to build a predictive model (and then explain it). Let’s build an xgboost model using the tidymodels ecosystem. If you’ve never heard of Tidymodels, it’s like Scikit Learn for R and CARET ecosystem.\r\nSelect Model Type: We use the boost_tree() function to establish that we are making a Boosted Tree\r\nSet the Mode: Using set_mode() we select classification because we are predicting a class label of patient.\r\nSet the Engine: Next we use set_engine() to tell Tidymodels to use the xgboost library.\r\nFit the Model: This performs a simple training of the model to fit each of the 5 predictors to the target diagnosis. Note that we did not perform cross-validation, hyperparameter tuning, or any advanced concepts as they are beyond the scope of this tutorial.\r\n\r\n\r\nfit_xgboost<- boost_tree(learn_rate = 0.3) %>% \r\n              set_mode(\"classification\") %>% \r\n              set_engine(\"xgboost\") %>% \r\n              fit(diagnosis~.,data=data_tbl)\r\n#fit_xgboost\r\n\r\n\r\nStep3: Make Explainer\r\nWith above predictive model, we are ready to create an explainer. In basic terms, an explainer is a consistent and unified way to explain predictive models. The explainer can accept many different model types like:\r\nTidymodels\r\nmlr3\r\nH2O\r\nPython Scikit Learn Models\r\nAnd it returns the explanation results from the model in a consistent format for investigation.\r\nNow, below is the code to create the explainer.\r\n\r\n\r\n#---------Explainer\r\nexplainer<-DALEX::explain(\r\n  model = fit_xgboost,\r\n  data= data_tbl[,-6],\r\n  y=as.numeric(unlist(data_tbl[,6])),\r\n  label = \"Extreme Gradient Boosting Machine (XGBoost)\"\r\n)\r\n\r\nPreparation of a new explainer is initiated\r\n-> model label : Extreme Gradient Boosting Machine (XGBoost)\r\n-> data : 569 rows 5 cols\r\n-> data : tibble converted into a data.frame\r\n-> target variable : 569 values\r\n-> predict function : yhat.model_fit will be used ( default )\r\n-> predicted values : No value for predict function target column. ( default )\r\n-> model_info : package parsnip , ver. 1.0.3 , task classification ( default )\r\n-> predicted values : numerical, min = 0.00912416 , mean = 0.6253965 , max = 0.9911299\r\n-> residual function : difference between y and yhat ( default )\r\n-> residuals : numerical, min = 0.1481095 , mean = 1.00202 , max = 1.515258\r\nA new explainer has been created!\r\n\r\nStep4: Run modelStudio\r\n\r\n\r\nmodStudio<-modelStudio::modelStudio(explainer = explainer)\r\n#modStudio\r\n\r\n\r\nAcknowledgement\r\n\r\nWe intensively express our recognition to the developers of modelStudio who are Hubert Baniecki and Przemyslaw Biecek. This package is part of the Dr. Why ecosystem of R packages, which are a collection of tools for Visual Exploration, Explanation and Debugging of Predictive Models. Thank you for everything you do, we owe you much respect to simplify our work.\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-11-14T16:14:22+02:00",
    "input_file": {}
  }
]
